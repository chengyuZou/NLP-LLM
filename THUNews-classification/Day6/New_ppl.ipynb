{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2415240-9c19-4914-8a3d-6a5a5da5b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f84fad8-4638-43c7-8676-5fe12a6efd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word: str):\n",
    "    synsets = wordnet.synsets(word)\n",
    "    synonyms = set()\n",
    "    for syn in synsets:\n",
    "        for lemma in syn.lemmas():\n",
    "            name = lemma.name().replace(\"_\", \" \")\n",
    "            if name.lower() != word.lower():\n",
    "                synonyms.add(name)\n",
    "    return list(synonyms)\n",
    "\n",
    "def synonym_replacement(sentence: str, n: int = 1) -> str:\n",
    "    \"\"\"\n",
    "    随机选 n 个可替换的单词，用其同义词替换。\n",
    "    \"\"\"\n",
    "    words = sentence.split()\n",
    "    # 可替换词：非停用词、长度>2 且有同义词\n",
    "    candidates = [w for w in set(words) if len(get_synonyms(w)) > 0]\n",
    "    random.shuffle(candidates)\n",
    "    num_replaced = 0\n",
    "    for w in candidates:\n",
    "        syns = get_synonyms(w)\n",
    "        if syns:\n",
    "            synonym = random.choice(syns)\n",
    "            # 全文替换该词的所有出现\n",
    "            sentence = sentence.replace(w, synonym, 1)\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "    return sentence\n",
    "def random_deletion(words, p=0.1):\n",
    "    # 每个词以 p 的概率删除\n",
    "    if len(words) == 1:\n",
    "        return words\n",
    "    return [w for w in words if random.random() > p]\n",
    "\n",
    "def random_swap(words, n_swaps=1):\n",
    "    words = words.copy()\n",
    "    n = len(words)\n",
    "    if n <= 2:\n",
    "        return words\n",
    "    for _ in range(n_swaps):\n",
    "        i, j = random.sample(range(n), 2)\n",
    "        words[i], words[j] = words[j], words[i]\n",
    "    return words\n",
    "\n",
    "def random_insertion(words, n_insert=1):\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n_insert):\n",
    "        candidates = [w for w in new_words if get_synonyms(w)]\n",
    "        if not candidates: break\n",
    "        word = random.choice(candidates)\n",
    "        synonym = random.choice(get_synonyms(word))\n",
    "        pos = random.randint(0, len(new_words))\n",
    "        new_words.insert(pos, synonym)\n",
    "    return new_words\n",
    "\n",
    "def eda_augment(sentence: str, alpha_sr=0.1, alpha_ri=0.1,\n",
    "                alpha_rs=0.1, p_rd=0.1, num_aug=1):\n",
    "    \"\"\"\n",
    "    对一句话生成 num_aug 条 EDA 增强样本\n",
    "    \"\"\"\n",
    "    words = list(jieba.cut(sentence))\n",
    "    augmented = []\n",
    "    n_sr = max(1, int(alpha_sr * len(words)))\n",
    "    n_ri = max(1, int(alpha_ri * len(words)))\n",
    "    n_rs = max(1, int(alpha_rs * len(words)))\n",
    "\n",
    "    # 1) 同义词替换\n",
    "    a_words = synonym_replacement(sentence, n_sr).split()\n",
    "    augmented.append(\" \".join(a_words))\n",
    "    # 2) 随机插入\n",
    "    a_words = random_insertion(words, n_ri)\n",
    "    augmented.append(\" \".join(a_words))\n",
    "    # 3) 随机交换\n",
    "    a_words = random_swap(words, n_rs)\n",
    "    augmented.append(\" \".join(a_words))\n",
    "    # 4) 随机删除\n",
    "    a_words = random_deletion(words, p_rd)\n",
    "    augmented.append(\" \".join(a_words))\n",
    "\n",
    "    # 随机选 num_aug 条返回\n",
    "    random.shuffle(augmented)\n",
    "    return augmented[:num_aug]\n",
    "    \n",
    "# def augment_examples(example):\n",
    "#     text = example[\"text\"]\n",
    "#     # 1) 同义词替换一条\n",
    "#     sr = synonym_replacement(text, n=2)\n",
    "#     # 2) EDA 生成两条\n",
    "#     eda_samples = eda_augment(text, alpha_sr=0.1, p_rd=0.1, num_aug=2)\n",
    "#     # 返回原文 + 三条增强\n",
    "#     augmented_texts = [text, sr] + eda_samples\n",
    "#     return {\"text\": str(augmented_texts),\n",
    "#             \"label\": [example[\"label\"]] * len(augmented_texts)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fafd0d35-dff1-4d81-a909-0758135bbef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 加载原始训练集\n",
    "ds = load_dataset(\"json\", data_files=\"train.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d648c195-06a6-4628-9452-af247c5d1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 数据预处理：tokenize\n",
    "label2id = {\"财经\": 0, \"体育\": 1, \"娱乐\": 2, \"教育\": 3, \"科技\": 4}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# 把字符串 label 映射为数字\n",
    "def encode_labels(example):\n",
    "    example[\"label\"] = label2id[example[\"label\"]]\n",
    "    return example\n",
    "ds = ds.map(encode_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d54424-a754-46f8-90bd-9233825c7aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f7f5804b9c4724ba43a43f42a91398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.824 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: out_texts, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: out_labels}\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 2. 批量 map，指定 features\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m aug_ds \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugment_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# 适当调速\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 3. 扁平化：把 List[List] → flat rows\u001b[39;00m\n\u001b[1;32m     33\u001b[0m aug_ds \u001b[38;5;241m=\u001b[39m aug_ds\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:3318\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[0m\n\u001b[1;32m   3316\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3317\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m unprocessed_kwargs \u001b[38;5;129;01min\u001b[39;00m unprocessed_kwargs_per_job:\n\u001b[0;32m-> 3318\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munprocessed_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3319\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcheck_if_shard_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3321\u001b[0m \u001b[38;5;66;03m# Avoids PermissionError on Windows (the error: https://github.com/huggingface/datasets/actions/runs/4026734820/jobs/6921621805)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:3674\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[0m\n\u001b[1;32m   3672\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3673\u001b[0m     _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 3674\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_iterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_examples_in_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3676\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mupdate_data\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:3624\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.iter_outputs\u001b[0;34m(shard_iterable)\u001b[0m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3623\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3624\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:3547\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function\u001b[0;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[1;32m   3545\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[1;32m   3546\u001b[0m inputs, fn_args, additional_args, fn_kwargs \u001b[38;5;241m=\u001b[39m prepare_inputs(pa_inputs, indices, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[0;32m-> 3547\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m, in \u001b[0;36maugment_examples\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     11\u001b[0m out_texts, out_labels \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m---> 14\u001b[0m     augmented \u001b[38;5;241m=\u001b[39m \u001b[43meda_augment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_aug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 生成 3 条增强文本\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# 原本那条也保留一份\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     all_texts \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;241m+\u001b[39m augmented\n",
      "Cell \u001b[0;32mIn[8], line 72\u001b[0m, in \u001b[0;36meda_augment\u001b[0;34m(sentence, alpha_sr, alpha_ri, alpha_rs, p_rd, num_aug)\u001b[0m\n\u001b[1;32m     70\u001b[0m augmented\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(a_words))\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# 2) 随机插入\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m a_words \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_insertion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_ri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m augmented\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(a_words))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# 3) 随机交换\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 49\u001b[0m, in \u001b[0;36mrandom_insertion\u001b[0;34m(words, n_insert)\u001b[0m\n\u001b[1;32m     47\u001b[0m new_words \u001b[38;5;241m=\u001b[39m words\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_insert):\n\u001b[0;32m---> 49\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m new_words \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mget_synonyms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     word \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(candidates)\n",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m, in \u001b[0;36mget_synonyms\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_synonyms\u001b[39m(word: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     synsets \u001b[38;5;241m=\u001b[39m \u001b[43mwordnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     synonyms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m syn \u001b[38;5;129;01min\u001b[39;00m synsets:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:1775\u001b[0m, in \u001b[0;36mWordNetCorpusReader.synsets\u001b[0;34m(self, lemma, pos, lang, check_exceptions)\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1771\u001b[0m         pos \u001b[38;5;241m=\u001b[39m POS_LIST\n\u001b[1;32m   1772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m   1773\u001b[0m         get_synset(p, offset)\n\u001b[1;32m   1774\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pos\n\u001b[0;32m-> 1775\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m form \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlemma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_exceptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1776\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m offset \u001b[38;5;129;01min\u001b[39;00m index[form]\u001b[38;5;241m.\u001b[39mget(p, [])\n\u001b[1;32m   1777\u001b[0m     ]\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1780\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_lang_data(lang)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:2109\u001b[0m, in \u001b[0;36mWordNetCorpusReader._morphy\u001b[0;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[1;32m   2106\u001b[0m     forms \u001b[38;5;241m=\u001b[39m apply_rules([form])\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;66;03m# 2. Return all that are in the database (and check the original too)\u001b[39;00m\n\u001b[0;32m-> 2109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfilter_forms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mform\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/nltk/corpus/reader/wordnet.py:2094\u001b[0m, in \u001b[0;36mWordNetCorpusReader._morphy.<locals>.filter_forms\u001b[0;34m(forms)\u001b[0m\n\u001b[1;32m   2092\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   2093\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m form \u001b[38;5;129;01min\u001b[39;00m forms:\n\u001b[0;32m-> 2094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m form \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lemma_pos_offset_map:\n\u001b[1;32m   2095\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lemma_pos_offset_map[form]:\n\u001b[1;32m   2096\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m form \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m seen:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datasets import Features, Sequence, Value\n",
    "\n",
    "# 1. 定义新 schema：text 变成一个列表序列\n",
    "new_features = Features({\n",
    "    \"text\": Sequence(feature=Value(\"string\")),     # 现在 text 列是 string 序列\n",
    "    \"label\":Sequence(feature=Value(\"int64\")),      # 假设 label 已经是 int\n",
    "})\n",
    "\n",
    "def augment_examples(batch):\n",
    "    # batch[\"text\"] 是 List[str]，batch[\"label\"] 是 List[int]\n",
    "    out_texts, out_labels = [], []\n",
    "\n",
    "    for text, label in zip(batch[\"text\"], batch[\"label\"]):\n",
    "        augmented = eda_augment(text, num_aug=3)  # 生成 3 条增强文本\n",
    "        # 原本那条也保留一份\n",
    "        all_texts = [text] + augmented\n",
    "        out_texts.append(all_texts)\n",
    "        # 每一条增强都用同一个 label\n",
    "        out_labels.append([label] * len(all_texts))\n",
    "\n",
    "    return {\"text\": out_texts, \"label\": out_labels}\n",
    "\n",
    "# 2. 批量 map，指定 features\n",
    "aug_ds = ds.map(\n",
    "    augment_examples,\n",
    "    batched=True,\n",
    "    batch_size=100,           # 适当调速\n",
    "    remove_columns=ds.column_names,\n",
    "    features=new_features,\n",
    ")\n",
    "\n",
    "# 3. 扁平化：把 List[List] → flat rows\n",
    "aug_ds = aug_ds.flatten()\n",
    "\n",
    "print(aug_ds)\n",
    "# 每行就变成了单条 text + 对应 label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759fda42-573b-4c2c-97d9-6284872bd6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['AC米兰至尊瑰宝身价全意甲第2 巴雷西他令我热血沸腾\\n\\u3000\\u3000新浪体育讯\\u3000帕托复出4场，打进5球，而恰恰AC米兰在这4场比赛中取得全胜拿到了12分，而在这4连胜之前，AC米兰则是一负二平，可见帕托对于AC米兰的重要性。\\n\\u3000\\u3000帕托对佛罗伦萨的进球，有人预料到了，因为帕托自加盟意甲以来就是“佛罗伦萨克星”，4战佛罗伦萨，每战必进球，而对亚特兰大的梅开二度却出乎宿命论者预料，登陆意甲之后，帕托还未攻破过亚特兰大的球门，而过去每次面对这个对手，帕托的表现都很糟糕，尤其是07/08赛季对阵亚特兰大之后，帕托一度成为了替补，但现在的帕托似乎已经是神挡杀神佛挡杀佛，面对昔日自己的“苦手”，以两个漂亮的进球成了比赛的决定性人物。就像巴雷西所说：“帕托的表现让AC米兰近几轮的攻击力改观了很多，他是一个绝对的天才，他的技术无与伦比，很难有人达到他的程度。帕托和巴洛特利是年轻球员当中的佼佼者，看他们踢球让我热血沸腾。”\\n\\u3000\\u3000其实从比赛的一开始，帕托就表现出了比前几轮更好的状态，27分钟，他在中路接到贝克汉姆的传球后，转身一领摆脱了帕多因的防守后，塞出直线球给插上的博列洛，可惜博列洛将球带入禁区后，把一对一的机会打偏。31分钟，帕托本场的第一次射门就攻破了对方球门，当时安布罗西尼接到小罗妙传，将球吊向后点，帕托看准来球与球门，张弓搭箭，将身体和右腿拉到和地面平行，面对凌空飞来的皮球停也不停，横身就打！尽管力量不算大，但帕托的动作干净利落一气呵成，球速很快，再加上他有意识将皮球打向地面，尽管本场亚特兰大的门将孔西利做出了不少精彩扑救，但对此球还是无能为力，指尖够了一下之后，皮球仍撞柱飞入网中！\\n\\u3000\\u3000而第二个进球更富戏剧性，帕托这一次又是接到小罗的助攻，反越位成功，横向一拨扣过封堵角度的门将孔西利，尽管曼弗雷迪尼奋力铲断，但由于皮球完全在帕托的控制范围之内，球依然是打到了帕托的脚上，撞进了面前的空门，进球后的帕托，显然对这一颇具戏剧性的得分非常喜悦--这是他本赛季的第12个进球，尽管之前伤停了5轮，在意甲射手榜上，帕托已经上升至第三位，而如果除去点球，单算运动战进球榜，帕托已经与国际米兰的迭戈-米利托并列第二！莱昂纳多赛前曾经表示：“帕托是一名长于一对一的球员，但他同时也是一个得分能力很强的射手。”这一次亚特兰大成为了印证这句话的试金石。\\n\\u3000\\u3000帕托的上一次梅开二度还是在赛季首轮，或许是这个原因，打进两个球的帕托一下进入了兴奋状态，不断的施展个人表演戏耍对手，第49分钟，帕托挑球过人，被贝利尼一脚踢倒，后者因此吃到了黄牌，1分钟后，帕托边路盘带40米吸引3名对方后卫后回敲贝克汉姆形成了不错空位传球机会，可惜小贝没能把握好，最精彩的一幕是在第53分钟，帕托接到队友的传球，面对扑抢上来的帕多因，将球一踩一挑，挑过了帕多因后，又用肩膀颠球过人--这已经完全是表演了，不堪受辱的帕多因不惜付出一张黄牌的代价一脚放倒了帕托。此外，说起来博内拉制造的那个点球，也来自帕托一次聪明的外脚背直传，AC米兰今天的三个进球，可以说都和帕托有直接关系！\\n\\u3000\\u3000但正所谓乐极生悲，就在帕托踢到最兴奋的时候，不幸的事情却发生了，比赛进行到77分钟，AC米兰后场发动反击，帕托后场拿球闪开对方的身后铲断，衔枚疾进，形成二打三的局面，但就在此时，帕托右腿忽然迈步出去，左腿跟着惯性跳了几步之后就痛苦倒地！当帕托被担架抬下时，显得痛苦万分，不过在经过简单的处理之后，帕托看起来没那么痛苦，他已经可以自己走回替补，再走回更衣室，赛后，莱昂纳多和加利亚尼都确认，帕托疼痛已经减轻，肌肉撕裂的可能已经排除，但即便如此，就像队友博列洛所说，“休息个两三周恐怕是免不了的”。\\n\\u3000\\u3000加利亚尼现在只能做祈祷了，“我担心他会错过对曼联的比赛，我希望他伤得轻一些，帕托的受伤对我们的影响会是巨大的，我们可能只能变阵了。”帕托很可能因此错过对罗马和曼联的比赛。\\n\\u3000\\u3000尽管伤病不断，帕托的这个赛季依然是一个成功的赛季，意大利《全市场》日前转载德国《转会网》的统计，目前意甲身价最高的球员是4000万的埃托奥，而帕托在《转会网》所标注的身价是3500万，是全意甲第二，但这只是理论上的价格，转会专家莫拉曾说：“切尔西如果出到6000万，AC米兰才有可能考虑考虑帕托的交易。”而经纪人帕斯奎林则表示“没有为AC米兰打进100球前，帕托是不可能离开的。”要知道，埃托奥的身价来自刚刚与伊布的交易标注的身价，而29岁的埃托奥，身价只可能会逐渐下降，而帕托的身价则来自他的升值，未满21岁的帕托身价会越来越高……\\n\\u3000\\u3000(沈飞)', 'AC米兰至尊瑰宝身价全意甲第2 巴雷西他令我热血沸腾 新浪体育讯 帕托复出4场，打进5球，而恰恰AC米兰在这4场比赛中取得全胜拿到了12分，而在这4连胜之前，AC米兰则是一负二平，可见帕托对于AC米兰的重要性。 帕托对佛罗伦萨的进球，有人预料到了，因为帕托自加盟意甲以来就是“佛罗伦萨克星”，4战佛罗伦萨，每战必进球，而对亚特兰大的梅开二度却出乎宿命论者预料，登陆意甲之后，帕托还未攻破过亚特兰大的球门，而过去每次面对这个对手，帕托的表现都很糟糕，尤其是07/08赛季对阵亚特兰大之后，帕托一度成为了替补，但现在的帕托似乎已经是神挡杀神佛挡杀佛，面对昔日自己的“苦手”，以两个漂亮的进球成了比赛的决定性人物。就像巴雷西所说：“帕托的表现让AC米兰近几轮的攻击力改观了很多，他是一个绝对的天才，他的技术无与伦比，很难有人达到他的程度。帕托和巴洛特利是年轻球员当中的佼佼者，看他们踢球让我热血沸腾。” 其实从比赛的一开始，帕托就表现出了比前几轮更好的状态，27分钟，他在中路接到贝克汉姆的传球后，转身一领摆脱了帕多因的防守后，塞出直线球给插上的博列洛，可惜博列洛将球带入禁区后，把一对一的机会打偏。31分钟，帕托本场的第一次射门就攻破了对方球门，当时安布罗西尼接到小罗妙传，将球吊向后点，帕托看准来球与球门，张弓搭箭，将身体和右腿拉到和地面平行，面对凌空飞来的皮球停也不停，横身就打！尽管力量不算大，但帕托的动作干净利落一气呵成，球速很快，再加上他有意识将皮球打向地面，尽管本场亚特兰大的门将孔西利做出了不少精彩扑救，但对此球还是无能为力，指尖够了一下之后，皮球仍撞柱飞入网中！ 而第二个进球更富戏剧性，帕托这一次又是接到小罗的助攻，反越位成功，横向一拨扣过封堵角度的门将孔西利，尽管曼弗雷迪尼奋力铲断，但由于皮球完全在帕托的控制范围之内，球依然是打到了帕托的脚上，撞进了面前的空门，进球后的帕托，显然对这一颇具戏剧性的得分非常喜悦--这是他本赛季的第12个进球，尽管之前伤停了5轮，在意甲射手榜上，帕托已经上升至第三位，而如果除去点球，单算运动战进球榜，帕托已经与国际米兰的迭戈-米利托并列第二！莱昂纳多赛前曾经表示：“帕托是一名长于一对一的球员，但他同时也是一个得分能力很强的射手。”这一次亚特兰大成为了印证这句话的试金石。 帕托的上一次梅开二度还是在赛季首轮，或许是这个原因，打进两个球的帕托一下进入了兴奋状态，不断的施展个人表演戏耍对手，第49分钟，帕托挑球过人，被贝利尼一脚踢倒，后者因此吃到了黄牌，1分钟后，帕托边路盘带40米吸引3名对方后卫后回敲贝克汉姆形成了不错空位传球机会，可惜小贝没能把握好，最精彩的一幕是在第53分钟，帕托接到队友的传球，面对扑抢上来的帕多因，将球一踩一挑，挑过了帕多因后，又用肩膀颠球过人--这已经完全是表演了，不堪受辱的帕多因不惜付出一张黄牌的代价一脚放倒了帕托。此外，说起来博内拉制造的那个点球，也来自帕托一次聪明的外脚背直传，AC米兰今天的三个进球，可以说都和帕托有直接关系！ 但正所谓乐极生悲，就在帕托踢到最兴奋的时候，不幸的事情却发生了，比赛进行到77分钟，AC米兰后场发动反击，帕托后场拿球闪开对方的身后铲断，衔枚疾进，形成二打三的局面，但就在此时，帕托右腿忽然迈步出去，左腿跟着惯性跳了几步之后就痛苦倒地！当帕托被担架抬下时，显得痛苦万分，不过在经过简单的处理之后，帕托看起来没那么痛苦，他已经可以自己走回替补，再走回更衣室，赛后，莱昂纳多和加利亚尼都确认，帕托疼痛已经减轻，肌肉撕裂的可能已经排除，但即便如此，就像队友博列洛所说，“休息个两三周恐怕是免不了的”。 加利亚尼现在只能做祈祷了，“我担心他会错过对曼联的比赛，我希望他伤得轻一些，帕托的受伤对我们的影响会是巨大的，我们可能只能变阵了。”帕托很可能因此错过对罗马和曼联的比赛。 尽管伤病不断，帕托的这个赛季依然是一个成功的赛季，意大利《全市场》日前转载德国《转会网》的统计，目前意甲身价最高的球员是4000万的埃托奥，而帕托在《转会网》所标注的身价是3500万，是全意甲第二，但这只是理论上的价格，转会专家莫拉曾说：“切尔西如果出到6000万，AC米兰才有可能考虑考虑帕托的交易。”而经纪人帕斯奎林则表示“没有为AC米兰打进100球前，帕托是不可能离开的。”要知道，埃托奥的身价来自刚刚与伊布的交易标注的身价，而29岁的埃托奥，身价只可能会逐渐下降，而帕托的身价则来自他的升值，未满21岁的帕托身价会越来越高…… (沈飞)', 'AC米兰至尊瑰宝身价全意甲第2 巴雷西他令我热血沸腾 新浪体育讯 帕托复出4场，打进5球，而恰恰AC米兰在这4场比赛中取得全胜拿到了12分，而在这4连胜之前，AC米兰则是一负二平，可见帕托对于AC米兰的重要性。 其实从比赛的一开始，帕托就表现出了比前几轮更好的状态，27分钟，他在中路接到贝克汉姆的传球后，转身一领摆脱了帕多因的防守后，塞出直线球给插上的博列洛，可惜博列洛将球带入禁区后，把一对一的机会打偏。31分钟，帕托本场的第一次射门就攻破了对方球门，当时安布罗西尼接到小罗妙传，将球吊向后点，帕托看准来球与球门，张弓搭箭，将身体和右腿拉到和地面平行，面对凌空飞来的皮球停也不停，横身就打！尽管力量不算大，但帕托的动作干净利落一气呵成，球速很快，再加上他有意识将皮球打向地面，尽管本场亚特兰大的门将孔西利做出了不少精彩扑救，但对此球还是无能为力，指尖够了一下之后，皮球仍撞柱飞入网中！ 帕托对佛罗伦萨的进球，有人预料到了，因为帕托自加盟意甲以来就是“佛罗伦萨克星”，4战佛罗伦萨，每战必进球，而对亚特兰大的梅开二度却出乎宿命论者预料，登陆意甲之后，帕托还未攻破过亚特兰大的球门，而过去每次面对这个对手，帕托的表现都很糟糕，尤其是07/08赛季对阵亚特兰大之后，帕托一度成为了替补，但现在的帕托似乎已经是神挡杀神佛挡杀佛，面对昔日自己的“苦手”，以两个漂亮的进球成了比赛的决定性人物。就像巴雷西所说：“帕托的表现让AC米兰近几轮的攻击力改观了很多，他是一个绝对的天才，他的技术无与伦比，很难有人达到他的程度。帕托和巴洛特利是年轻球员当中的佼佼者，看他们踢球让我热血沸腾。” 而第二个进球更富戏剧性，帕托这一次又是接到小罗的助攻，反越位成功，横向一拨扣过封堵角度的门将孔西利，尽管曼弗雷迪尼奋力铲断，但由于皮球完全在帕托的控制范围之内，球依然是打到了帕托的脚上，撞进了面前的空门，进球后的帕托，显然对这一颇具戏剧性的得分非常喜悦--这是他本赛季的第12个进球，尽管之前伤停了5轮，在意甲射手榜上，帕托已经上升至第三位，而如果除去点球，单算运动战进球榜，帕托已经与国际米兰的迭戈-米利托并列第二！莱昂纳多赛前曾经表示：“帕托是一名长于一对一的球员，但他同时也是一个得分能力很强的射手。”这一次亚特兰大成为了印证这句话的试金石。 帕托的上一次梅开二度还是在赛季首轮，或许是这个原因，打进两个球的帕托一下进入了兴奋状态，不断的施展个人表演戏耍对手，第49分钟，帕托挑球过人，被贝利尼一脚踢倒，后者因此吃到了黄牌，1分钟后，帕托边路盘带40米吸引3名对方后卫后回敲贝克汉姆形成了不错空位传球机会，可惜小贝没能把握好，最精彩的一幕是在第53分钟，帕托接到队友的传球，面对扑抢上来的帕多因，将球一踩一挑，挑过了帕多因后，又用肩膀颠球过人--这已经完全是表演了，不堪受辱的帕多因不惜付出一张黄牌的代价一脚放倒了帕托。此外，说起来博内拉制造的那个点球，也来自帕托一次聪明的外脚背直传，AC米兰今天的三个进球，可以说都和帕托有直接关系！ 但正所谓乐极生悲，就在帕托踢到最兴奋的时候，不幸的事情却发生了，比赛进行到77分钟，AC米兰后场发动反击，帕托后场拿球闪开对方的身后铲断，衔枚疾进，形成二打三的局面，但就在此时，帕托右腿忽然迈步出去，左腿跟着惯性跳了几步之后就痛苦倒地！当帕托被担架抬下时，显得痛苦万分，不过在经过简单的处理之后，帕托看起来没那么痛苦，他已经可以自己走回替补，再走回更衣室，赛后，莱昂纳多和加利亚尼都确认，帕托疼痛已经减轻，肌肉撕裂的可能已经排除，但即便如此，就像队友博列洛所说，“休息个两三周恐怕是免不了的”。 加利亚尼现在只能做祈祷了，“我担心他会错过对曼联的比赛，我希望他伤得轻一些，帕托的受伤对我们的影响会是巨大的，我们可能只能变阵了。”帕托很可能因此错过对罗马和曼联的比赛。 尽管伤病不断，帕托的这个赛季依然是一个成功的赛季，意大利《全市场》日前转载德国《转会网》的统计，目前意甲身价最高的球员是4000万的埃托奥，而帕托在《转会网》所标注的身价是3500万，是全意甲第二，但这只是理论上的价格，转会专家莫拉曾说：“切尔西如果出到6000万，AC米兰才有可能考虑考虑帕托的交易。”而经纪人帕斯奎林则表示“没有为AC米兰打进100球前，帕托是不可能离开的。”要知道，埃托奥的身价来自刚刚与伊布的交易标注的身价，而29岁的埃托奥，身价只可能会逐渐下降，而帕托的身价则来自他的升值，未满21岁的帕托身价会越来越高…… (沈飞)', 'AC米兰至尊瑰宝身价全意甲第2 巴雷西他令我热血沸腾 新浪体育讯 帕托复出4场，打进5球，而恰恰AC米兰在这4场比赛中取得全胜拿到了12分，而在这4连胜之前，AC米兰则是一负二平，可见帕托对于AC米兰的重要性。 帕托对佛罗伦萨的进球，有人预料到了，因为帕托自加盟意甲以来就是“佛罗伦萨克星”，4战佛罗伦萨，每战必进球，而对亚特兰大的梅开二度却出乎宿命论者预料，登陆意甲之后，帕托还未攻破过亚特兰大的球门，而过去每次面对这个对手，帕托的表现都很糟糕，尤其是07/08赛季对阵亚特兰大之后，帕托一度成为了替补，但现在的帕托似乎已经是神挡杀神佛挡杀佛，面对昔日自己的“苦手”，以两个漂亮的进球成了比赛的决定性人物。就像巴雷西所说：“帕托的表现让AC米兰近几轮的攻击力改观了很多，他是一个绝对的天才，他的技术无与伦比，很难有人达到他的程度。帕托和巴洛特利是年轻球员当中的佼佼者，看他们踢球让我热血沸腾。” 其实从比赛的一开始，帕托就表现出了比前几轮更好的状态，27分钟，他在中路接到贝克汉姆的传球后，转身一领摆脱了帕多因的防守后，塞出直线球给插上的博列洛，可惜博列洛将球带入禁区后，把一对一的机会打偏。31分钟，帕托本场的第一次射门就攻破了对方球门，当时安布罗西尼接到小罗妙传，将球吊向后点，帕托看准来球与球门，张弓搭箭，将身体和右腿拉到和地面平行，面对凌空飞来的皮球停也不停，横身就打！尽管力量不算大，但帕托的动作干净利落一气呵成，球速很快，再加上他有意识将皮球打向地面，尽管本场亚特兰大的门将孔西利做出了不少精彩扑救，但对此球还是无能为力，指尖够了一下之后，皮球仍撞柱飞入网中！ 而第二个进球更富戏剧性，帕托这一次又是接到小罗的助攻，反越位成功，横向一拨扣过封堵角度的门将孔西利，尽管曼弗雷迪尼奋力铲断，但由于皮球完全在帕托的控制范围之内，球依然是打到了帕托的脚上，撞进了面前的空门，进球后的帕托，显然对这一颇具戏剧性的得分非常喜悦--这是他本赛季的第12个进球，尽管之前伤停了5轮，在意甲射手榜上，帕托已经上升至第三位，而如果除去点球，单算运动战进球榜，帕托已经与国际米兰的迭戈-米利托并列第二！莱昂纳多赛前曾经表示：“帕托是一名长于一对一的球员，但他同时也是一个得分能力很强的射手。”这一次亚特兰大成为了印证这句话的试金石。 帕托的上一次梅开二度还是在赛季首轮，或许是这个原因，打进两个球的帕托一下进入了兴奋状态，不断的施展个人表演戏耍对手，第49分钟，帕托挑球过人，被贝利尼一脚踢倒，后者因此吃到了黄牌，1分钟后，帕托边路盘带40米吸引3名对方后卫后回敲贝克汉姆形成了不错空位传球机会，可惜小贝没能把握好，最精彩的一幕是在第53分钟，帕托接到队友的传球，面对扑抢上来的帕多因，将球一踩一挑，挑过了帕多因后，又用肩膀颠球过人--这已经完全是表演了，不堪受辱的帕多因不惜付出一张黄牌的代价一脚放倒了帕托。此外，说起来博内拉制造的那个点球，也来自帕托一次聪明的外脚背直传，AC米兰今天的三个进球，可以说都和帕托有直接关系！ 但正所谓乐极生悲，就在帕托踢到最兴奋的时候，不幸的事情却发生了，比赛进行到77分钟，AC米兰后场发动反击，帕托后场拿球闪开对方的身后铲断，衔枚疾进，形成二打三的局面，但就在此时，帕托右腿忽然迈步出去，左腿跟着惯性跳了几步之后就痛苦倒地！当帕托被担架抬下时，显得痛苦万分，不过在经过简单的处理之后，帕托看起来没那么痛苦，他已经可以自己走回替补，再走回更衣室，赛后，莱昂纳多和加利亚尼都确认，帕托疼痛已经减轻，肌肉撕裂的可能已经排除，但即便如此，就像队友博列洛所说，“休息个两三周恐怕是免不了的”。 加利亚尼现在只能做祈祷了，“我担心他会错过对曼联的比赛，我希望他伤得轻一些，帕托的受伤对我们的影响会是巨大的，我们可能只能变阵了。”帕托很可能因此错过对罗马和曼联的比赛。 尽管伤病不断，帕托的这个赛季依然是一个成功的赛季，意大利《全市场》日前转载德国《转会网》的统计，目前意甲身价最高的球员是4000万的埃托奥，而帕托在《转会网》所标注的身价是3500万，是全意甲第二，但这只是理论上的价格，转会专家莫拉曾说：“切尔西如果出到6000万，AC米兰才有可能考虑考虑帕托的交易。”而经纪人帕斯奎林则表示“没有为AC米兰打进100球前，帕托是不可能离开的。”要知道，埃托奥的身价来自刚刚与伊布的交易标注的身价，而29岁的埃托奥，身价只可能会逐渐下降，而帕托的身价则来自他的升值，未满21岁的帕托身价会越来越高…… (沈飞)'], 'label': [1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(aug_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4dd04b9-90b7-4577-b2ae-76a34b066a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 36000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "texts, labels = [], []\n",
    "for example in ds:\n",
    "    orig_text, orig_label = example[\"text\"], example[\"label\"]\n",
    "    # 原本一条 + 3 条增强\n",
    "    aug_texts = [orig_text] + eda_augment(orig_text, num_aug=3)\n",
    "    texts.extend(aug_texts)\n",
    "    labels.extend([orig_label] * len(aug_texts))\n",
    "\n",
    "aug_ds = Dataset.from_dict({\"text\": texts, \"label\": labels})\n",
    "print(aug_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf527c-55fd-47b6-8e73-32e1fb058147",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_ds.to_json(\"THUCNews_augmented.jsonl\", orient=\"records\", lines=True, force_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
